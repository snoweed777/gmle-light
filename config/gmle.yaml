anki:
  card_template:
    back: null
    css: ''
    front: null
  deck_bank_prefix: 'GMLE::Bank::'
  note_type_name: GMLE_MCQA
api:
  anki:
    connect_url: http://host.docker.internal:8765
    connect_version: 6
  readwise:
    api_url: https://readwise.io/api/v2/highlights/
http:
  max_retries: 3
  retry_backoff_base: 2
  timeout: 120
ingest:
  excerpt_max: 650
  excerpt_min: 200
  quarantine_min_length: 200
llm:
  active_provider: huggingface
  providers:
    cohere:
      api_url: https://api.cohere.ai/v1/chat
      available_models:
      - command-a-03-2025
      - command-r-plus
      default_model: command-a-03-2025
    gemini:
      api_url: https://generativelanguage.googleapis.com/v1beta
      available_models:
      - gemini-2.5-flash
      - gemini-2.5-pro
      - gemini-2.0-flash
      - gemini-1.5-pro
      - gemini-1.5-flash
      default_model: gemini-2.0-flash
    groq:
      api_url: https://api.groq.com/openai/v1
      available_models:
      - llama-3.1-8b-instant
      - llama-3.3-70b-versatile
      - mixtral-8x7b-32768
      - gemma-7b-it
      - gemma2-9b-it
      default_model: llama-3.3-70b-versatile
    huggingface:
      api_url: https://router.huggingface.co/v1
      available_models:
      - meta-llama/Llama-3.2-1B-Instruct
      - meta-llama/Llama-3.2-3B-Instruct
      - Qwen/Qwen2.5-72B-Instruct
      - mistralai/Mistral-7B-Instruct-v0.3
      - microsoft/Phi-3.5-mini-instruct
      default_model: meta-llama/Llama-3.2-3B-Instruct
lock:
  stale_seconds: 3600
logging:
  file: null
  format: human
  level: INFO
  rotation_days: 30
params:
  coverage: 6
  domain_cap_steps:
  - 6
  - 7
  - 8
  - 9999
  excerpt_max: 800
  excerpt_min: 200
  improve: 7
  maintain_total: 20
  new_total: 10
  rationale_quote_max: 100
  reward_cap: 3
  total: 30
prompts:
  stage1_extract:
    description: 'Stage 1: Fact extraction prompt (English for better LLM understanding)'
    template: "Extract important facts from the following text.\n\nIMPORTANT: Write fact text in JAPANESE, but follow this JSON structure strictly.\n\n\
      TEXT:\n{excerpt}\n\nRETURN STRICTLY in this JSON format (NO markdown, NO extra text):\n\
      {{\n  \"facts\": [\n    {{\"id\": \"f1\", \"text\": \"<fact in Japanese>\", \"support_quote\": \"<quote from text>\"}}\n  ]\n}}\n\n\
      REQUIRED fields:\n- id: fact identifier (f1, f2, ...)\n- text: fact description in JAPANESE\n- support_quote: exact quote from the original text\n\n\
      Example:\n{{\n  \"facts\": [\n    {{\"id\": \"f1\", \"text\": \"Pythonは1991年にGuido van Rossumによって開発されたプログラミング言語です\", \"support_quote\": \"Python was created by Guido van Rossum in 1991\"}}\n  ]\n}}\n"
  stage2_build_mcq:
    description: 'Stage 2: MCQ generation prompt (English for better LLM understanding)'
    template: "Create a multiple-choice question (MCQ) from the following facts.\n\n\
      IMPORTANT: Write question, choices, and explanation in JAPANESE, but follow this JSON structure strictly.\n\n\
      FACTS:\n{facts}\n\nRETURN STRICTLY in this JSON format (NO markdown, NO extra text):\n\
      {{\n  \"question\": \"<question in Japanese>\",\n  \"choices\": [\"A: <choice 1 in Japanese>\", \"B: <choice 2 in Japanese>\", \"C: <choice 3 in Japanese>\", \"D: <choice 4 in Japanese>\"],\n  \"answer\": \"A\",\n  \"rationale\": {{\n    \"text\": \"<explanation in Japanese>\",\n    \"quote\": \"<quote from text, max 100 chars>\"\n  }}\n}}\n\n\
      REQUIRED fields (ALL must be present):\n- question: question text in JAPANESE\n- choices: exactly 4 choices (A/B/C/D) in JAPANESE\n- answer: correct answer (must be A, B, C, or D)\n- rationale.text: explanation in JAPANESE\n- rationale.quote: exact quote from original text (max 100 characters)\n\n\
      Example:\n{{\n  \"question\": \"Pythonが最初にリリースされた年はいつですか？\",\n  \"choices\": [\"A: 1989年\", \"B: 1991年\", \"C: 1995年\", \"D: 2000年\"],\n  \"answer\": \"B\",\n  \"rationale\": {{\n    \"text\": \"Pythonは1991年にGuido van Rossumによって最初にリリースされました\",\n    \"quote\": \"Python was created by Guido van Rossum in 1991\"\n  }}\n}}\n"
rate_limit:
  burst_limit: 1
  call_type_limits:
    api_key_check:
      requests_per_day: 50
      requests_per_hour: 100
      requests_per_minute: 60
    mcq_generation:
      requests_per_day: 800
      requests_per_hour: 40
      requests_per_minute: 10
    prerequisite_check:
      requests_per_day: 50
      requests_per_hour: 100
      requests_per_minute: 60
  concurrent_requests: 3
  cooldown_seconds: 60
  enabled: true
  provider_daily_limits:
    cohere: 900
    gemini: 1400
    groq: 360
    huggingface: 900
  requests_per_day: 360
  requests_per_hour: 15
  requests_per_minute: 1
  requests_per_second: 0.014
version: '1.0'
